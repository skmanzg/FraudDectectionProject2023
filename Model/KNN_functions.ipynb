{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7427a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61cc2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColumnsExtractor(data):\n",
    "    reduced_data = data[data[\"AMT\", \"TRANS_MONTH\", \"TRANS_DAY\", \"TRANS_HOUR\", \"CATEGORY\", \"IS_FRAUD\"]]\n",
    "    reduced_data = reduced_data[\"IS_FRAUD\"].astype(\"int\")\n",
    "    reduced_data.to_csv(\"reduced_data.csv\",index=False) #디버깅용\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0888c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNforFraud(df, isLearn, beta, delta1, epsilon):\n",
    "    if(not isLearn):\n",
    "        #학습이 아닌 추론일 때만 사용됨\n",
    "        df_train_x = pd.read_csv(\"../data/splitted/Fraud_Detection_train_features.csv\", index_col=0)\n",
    "    \n",
    "    reduced_data = ColumnsExtractor(df)\n",
    "    \n",
    "    #MinMaxScaler 함수로 객체만들고 scaled된 reduced_data_scaled 만들기\n",
    "    MMscaler = MinMaxScaler()\n",
    "    if(isLearn):\n",
    "        MMscaler.fit(reduced_data)\n",
    "        reduced_data_scaled = MMscaler.transfrom(reduced_data)\n",
    "        reduced_data_scaled = pd.DataFrame(reduced_data_scaled, columns=[\"AMT\", \"TRANS_MONTH\", \"TRANS_DAY\", \"TRANS_HOUR\", \"CATEGORY\", \"IS_FRAUD\"])\n",
    "    else:\n",
    "        #학습용 데이터 맨 아래에 임시로 행을 붙인 뒤 다시 뗀다\n",
    "        df_temp = pd.concat([df_train_x, reduced_data])\n",
    "        MMscaler.fit(df_temp)\n",
    "        df_temp2 = MMscaler.transfrom(df_temp)\n",
    "        df_temp2 = pd.DataFrame(df_temp2, columns=[\"AMT\", \"TRANS_MONTH\", \"TRANS_DAY\", \"TRANS_HOUR\", \"CATEGORY\", \"IS_FRAUD\"])\n",
    "        reduced_data_scaled = df_temp2.tail(1)\n",
    "\n",
    "    #5개의 KNN 객체 생성. parameter는 반드시 odd number로!\n",
    "    global kn1\n",
    "    global kn2\n",
    "    global kn3\n",
    "    global kn4\n",
    "    global kn5\n",
    "    \n",
    "    global FCmodel\n",
    "    \n",
    "    if(isLearn):\n",
    "        kn1 = KNeighborsClassifier(n_neighbors=3)\n",
    "        kn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "        kn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "        kn4 = KNeighborsClassifier(n_neighbors=3)\n",
    "        kn5 = KNeighborsClassifier(n_neighbors=3)\n",
    "        \n",
    "        kn1.fit(reduced_data_scaled[\"AMT\"], reduced_data_scaled[\"IS_FRAUD\"])\n",
    "        kn2.fit(reduced_data_scaled[\"TRANS_MONTH\"], reduced_data_scaled[\"IS_FRAUD\"])\n",
    "        kn3.fit(reduced_data_scaled[\"TRANS_DAY\"], reduced_data_scaled[\"IS_FRAUD\"])\n",
    "        kn4.fit(reduced_data_scaled[\"TRANS_HOUR\"], reduced_data_scaled[\"IS_FRAUD\"])\n",
    "        kn5.fit(reduced_data_scaled[\"CATEGORY\"], reduced_data_scaled[\"IS_FRAUD\"])\n",
    "        arr1 = kn1.predict_proba(reduced_data_scaled[\"AMT\"])\n",
    "        arr2 = kn2.predict_proba(reduced_data_scaled[\"TRANS_MONTH\"])\n",
    "        arr3 = kn3.predict_proba(reduced_data_scaled[\"TRANS_DAY\"])\n",
    "        arr4 = kn4.predict_proba(reduced_data_scaled[\"TRANS_HOUR\"])\n",
    "        arr5 = kn5.predict_proba(reduced_data_scaled[\"CATEGORY\"])\n",
    "        \n",
    "        #arr1~5를 하나의 numpy 배열로 합칠 것이다. 하나의 데이터는 하나의 행이다.\n",
    "        NNinput = arr1[:,1]\n",
    "        NNinput = np.append(NNinput, arr2[:,1], axis=1)\n",
    "        NNinput = np.append(NNinput, arr3[:,1], axis=1)\n",
    "        NNinput = np.append(NNinput, arr4[:,1], axis=1)\n",
    "        NNinput = np.append(NNinput, arr5[:,1], axis=1)\n",
    "        NNoutput = np.array(reduced_data_scaled[\"IS_FRAUD\"].to_list())\n",
    "        NNoutput = NNoutput.T\n",
    "        \n",
    "        #Fully Connected층을 epoch = epsilon횟수로 학습\n",
    "        FCmodel = keras.Sequential()\n",
    "        FCmodel.add(keras.layers.Dense(beta))\n",
    "        FCmodel.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "        FCmodel.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "        FCmodel.fit(NNinput, NNoutput, epochs=epsilon)\n",
    "        return 2\n",
    "    else:\n",
    "        arr1 = kn1.predict_proba(reduced_data_scaled[\"AMT\"])\n",
    "        arr2 = kn2.predict_proba(reduced_data_scaled[\"TRANS_MONTH\"])\n",
    "        arr3 = kn3.predict_proba(reduced_data_scaled[\"TRANS_DAY\"])\n",
    "        arr4 = kn4.predict_proba(reduced_data_scaled[\"TRANS_HOUR\"])\n",
    "        arr5 = kn5.predict_proba(reduced_data_scaled[\"CATEGORY\"])\n",
    "        \n",
    "        arr1 = arr1[:,1]\n",
    "        arr2 = arr2[:,1]\n",
    "        arr3 = arr3[:,1]\n",
    "        arr4 = arr4[:,1]\n",
    "        arr5 = arr5[:,1]\n",
    "        \n",
    "        arr_input = arr1\n",
    "        arr_input = np.append(arr_input, arr2)\n",
    "        arr_input = np.append(arr_input, arr3)\n",
    "        arr_input = np.append(arr_input, arr4)\n",
    "        arr_input = np.append(arr_input, arr5)\n",
    "        \n",
    "        fraud_prob = FCmodel.predict(arr_input)\n",
    "        return fraud_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
